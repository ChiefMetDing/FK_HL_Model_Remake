{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "#from sqlalchemy import create_engine\r\n",
    "#import psycopg2\r\n",
    "#from config import db_password,g_key\r\n",
    "from config import resolution,lat_max,lat_min,lng_max,lng_min\r\n",
    "from config import t_sat,flow_rate,project_span\r\n",
    "import json\r\n",
    "#from shapely.geometry import Point,shape\r\n",
    "import os\r\n",
    "from datetime import datetime,timedelta,date\r\n",
    "from functions import Rmax_calc,recovery_calc,month_index\r\n",
    "import scipy.optimize\r\n",
    "from geojson import Feature, FeatureCollection, Polygon"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# blocks information\r\n",
    "file_path = os.path.join('..','..','Resources','blocks_info.csv')\r\n",
    "blocks_df = pd.read_csv(file_path)\r\n",
    "# actual gold produciton by month\r\n",
    "file_path = os.path.join('..','..','Resources','act_monthly_oz.csv')\r\n",
    "act_oz_df = pd.read_csv(file_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Convert to datetime format\r\n",
    "blocks_df['stack_finish'] = pd.to_datetime(blocks_df['stack_finish'])\r\n",
    "blocks_df['leach_start'] = pd.to_datetime(blocks_df['leach_start'])\r\n",
    "blocks_df['leach_end'] = pd.to_datetime(blocks_df['leach_end'])\r\n",
    "blocks_df['leach_days'] = blocks_df['leach_end']-blocks_df['leach_start']\r\n",
    "lat_lng_list = blocks_df[['lat','lng']].values.tolist()\r\n",
    "# Create a dataframe with sequence as block_id, lift and lat_lng as columns\r\n",
    "block_leach_time = pd.DataFrame(blocks_df[['lift']])\r\n",
    "block_leach_time['lat_lng']=blocks_df[['lat','lng']].values.tolist()\r\n",
    "block_leach_time.index.name = 'block_id'\r\n",
    "# Create block_list for later index reference.\r\n",
    "block_list = block_leach_time.index.tolist()\r\n",
    "\r\n",
    "# Set up project span\r\n",
    "projectspan = (\r\n",
    "    datetime.strptime(project_span['startdate'],'%Y-%m-%d'),\r\n",
    "    datetime.strptime(project_span['enddate'],'%Y-%m-%d')\r\n",
    "    )\r\n",
    "# Create month list of the project\r\n",
    "startyear = projectspan[0].year\r\n",
    "startmonth = projectspan[0].month\r\n",
    "endyear = projectspan[1].year\r\n",
    "endmonth = projectspan[1].month\r\n",
    "monthlist = [datetime(m//12, m%12+1, 1) for m in range(startyear*12+startmonth-1, endyear*12+endmonth)]\r\n",
    "# Use monthlist create recovery dataframe\r\n",
    "leach_days_df = pd.DataFrame(monthlist,columns = ['months'])\r\n",
    "leach_ks_df = pd.DataFrame(monthlist,columns = ['months'])\r\n",
    "leach_rec_df = pd.DataFrame(monthlist,columns = ['months'])\r\n",
    "leach_ozs_df = pd.DataFrame(monthlist,columns = ['months'])\r\n",
    "\r\n",
    "# Break dataframe to records\r\n",
    "blocks_records = blocks_df.to_records(index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# This block of code calculates a specific block's recovery over months.\r\n",
    "## The function takes two block indices \r\n",
    "## and the k factor that is going to be used for recovery calculation.\r\n",
    "def block_leach_days(i,ref,lift_diff):\r\n",
    "    # if the two indices are the same, means this is calculating the primary leach recovery\r\n",
    "    calc_block = blocks_records[i]\r\n",
    "    if i == ref:\r\n",
    "        start_date = pd.to_datetime(calc_block['leach_start'])\r\n",
    "        end_date = pd.to_datetime(calc_block['leach_end'])\r\n",
    "    # if the two indices are different, means calculating recoveries of blocks under secondary leach\r\n",
    "    else:\r\n",
    "        # ref_block is the block on the very top\r\n",
    "        ref_block = blocks_records[ref]\r\n",
    "        # the blocks below the ref_block inherit the leaching dates from the ref_block\r\n",
    "        # calculate leach delay\r\n",
    "        start_date = pd.to_datetime(ref_block['leach_start']) + timedelta(days = t_sat + round(lift_diff * flow_rate))\r\n",
    "        end_date = pd.to_datetime(ref_block['leach_end']) + timedelta(days = round(lift_diff * flow_rate))\r\n",
    "    # locate the month row\r\n",
    "    m_index = month_index(start_date,projectspan)\r\n",
    "    start_month = start_date.month\r\n",
    "    end_month = end_date.month + (end_date.year - start_date.year) * 12\r\n",
    "    # calcuate how much recovery that this block has achieved since the start\r\n",
    "    for m in range(start_month,end_month+1):\r\n",
    "        # calculate how many days in this month for recovery calculation\r\n",
    "        if m == start_month:\r\n",
    "            if m == 12:\r\n",
    "                days = 31 - start_date.day\r\n",
    "            else:\r\n",
    "                days = (datetime(start_date.year,start_date.month+1,1)-start_date).days\r\n",
    "        elif m == end_month:\r\n",
    "            days = end_date.day\r\n",
    "        elif m < 12:\r\n",
    "            days = (datetime(start_date.year,m+1,1)-datetime(start_date.year,m,1)).days\r\n",
    "        elif m == 12:\r\n",
    "            days = 31\r\n",
    "        else:\r\n",
    "            days = (datetime(start_date.year+1,m-12+1,1)-datetime(start_date.year+1,m-12,1)).days\r\n",
    "        # write the recovery to the rec_df.\r\n",
    "        leach_days_df.at[m_index,i] = days\r\n",
    "        m_index += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def create_leach_days_df():\r\n",
    "    for high in block_list:\r\n",
    "        leach_days_df[high]=0\r\n",
    "        lift_diff = 0\r\n",
    "        block_leach_days(high,high,lift_diff)\r\n",
    "        high_lift = blocks_records[high]['lift']\r\n",
    "        for low in range(0,high):\r\n",
    "            if lat_lng_list[high]==lat_lng_list[low]:\r\n",
    "                low_lift = blocks_records[low]['lift']\r\n",
    "                lift_diff = high_lift-low_lift\r\n",
    "                block_leach_days(low,high,lift_diff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Have no idea why this function has to be ran twice to make the records the same as the dataframe\r\n",
    "create_leach_days_df()\r\n",
    "create_leach_days_df()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(leach_days_df[1000].tolist())\r\n",
    "leach_days_records = leach_days_df.to_records()\r\n",
    "print(leach_days_records['1000'].tolist())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 0, 0, 3, 31, 29, 0, 0, 0, 23, 31, 29, 6, 15, 31, 30, 31, 11, 28, 31, 30, 29, 0, 0, 0, 10, 31, 30, 29, 0, 23, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 3, 31, 29, 0, 0, 0, 23, 31, 29, 6, 15, 31, 30, 31, 11, 28, 31, 30, 29, 0, 0, 0, 10, 31, 30, 29, 0, 23, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Prepare k factors\r\n",
    "def k_calc(k):\r\n",
    "    for b in block_list:\r\n",
    "        leach_ks_df[b] = k\r\n",
    "        leach_rec_df[b] = 0.0\r\n",
    "    return leach_ks_df,leach_rec_df\r\n",
    "leach_ks_df,leach_rec_df = k_calc(0.005)\r\n",
    "# leach_ozs_df = leach_rec_df.copy()\r\n",
    "# Prepare Rmax\r\n",
    "rmax = blocks_df['rmax']\r\n",
    "cont_ozs = blocks_df['ounces_per_block']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "leach_ks_records = leach_ks_df.to_records(index=False)\r\n",
    "leach_days_records = leach_days_df.to_records(index=False)\r\n",
    "leach_rec_records = leach_rec_df.to_records(index=False)\r\n",
    "#leach_ozs_records = leach_ozs_df.to_records(index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def rec_monthly(k):\r\n",
    "    for b in block_list:\r\n",
    "        rcum = 0\r\n",
    "        b_rec = leach_rec_records[f'{b}']\r\n",
    "        for m in range(0,len(monthlist)):\r\n",
    "            # b_rec[m] = recovery_calc(rmax[b],rcum,leach_ks_records[f'{b}'][m],leach_days_records[f'{b}'][m])\r\n",
    "            b_rec[m] = recovery_calc(rmax[b],rcum,k,leach_days_records[f'{b}'][m])\r\n",
    "            rcum += b_rec[m]\r\n",
    "        leach_ozs_df[b] = b_rec * cont_ozs[b]\r\n",
    "        #leach_rec_records[f'{b}'] = b_rec\r\n",
    "    model_monthly = leach_ozs_df.sum(axis=1)\r\n",
    "    #leach_ozs_df['oz_monthly'] = model_monthly\r\n",
    "    return model_monthly"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimize K value to make model close to actual"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "current_date = date.today()\r\n",
    "opt_till = month_index(current_date,projectspan)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def sq(k):\r\n",
    "    # use this k to calculate gold production\r\n",
    "    model_rec = rec_monthly(k)[:opt_till]\r\n",
    "    actual_rec = act_oz_df.iloc[:opt_till]['ounces']\r\n",
    "    delta = np.nansum((actual_rec-model_rec)**2)\r\n",
    "    # delta = abs(calculated recovery - actual recovery)\r\n",
    "    return delta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "initial_k = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Check other options and see steps.\r\n",
    "opt1 = scipy.optimize.minimize(sq,initial_k,method='BFGS',tol=100)\r\n",
    "print(f'opt 1 error is {opt1.fun}, when k is {opt1.x[0]}')\r\n",
    "opt2 = scipy.optimize.minimize(sq,initial_k,method='Nelder-Mead',tol=100,bounds=[(0.000001,0.020001)])\r\n",
    "print(f'opt 2 error is {opt2.fun}, when k is {opt2.x[0]}')\r\n",
    "if opt1.fun > opt2.fun:\r\n",
    "    k_to_use = opt2.x[0]\r\n",
    "    print(f'Chose to use opt 2')\r\n",
    "else:\r\n",
    "    k_to_use = opt1.x[0]\r\n",
    "    print(f'Chose to use opt 1')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "opt 1 error is 2.3585828331520544e-05, when k is 0.005999992541362125\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\dzhang\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:535: RuntimeWarning: Method Nelder-Mead cannot handle constraints nor bounds.\n",
      "  warn('Method %s cannot handle constraints nor bounds.' % method,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "opt 2 error is 1052.4129341931457, when k is 0.006050000000000018\n",
      "Chose to use opt 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Data For Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "monthly_oz = rec_monthly(k_to_use)\r\n",
    "leach_ozs_df['oz_monthly'] = monthly_oz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# This function is to calculate the remaining ounces of blocks without leaching\r\n",
    "def init_oz(X):\r\n",
    "    # input X is the dataframe's row in a series\r\n",
    "    m_place = month_index(X[-2],projectspan)\r\n",
    "    Y = X.copy()\r\n",
    "    Y[m_place + 2:-2] = Y[-1]\r\n",
    "    return Y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Creating cells gold production stats by month.\r\n",
    "blocks_oz_df = leach_ozs_df.set_index('months').T\r\n",
    "\r\n",
    "## Export the data for visualization\r\n",
    "file_path = os.path.join('..','..','Resources','blocks_oz.json')\r\n",
    "blocks_oz_df.to_json(file_path)\r\n",
    "blocks_oz_df.drop(blocks_oz_df.tail(1).index,inplace=True)\r\n",
    "\r\n",
    "## Insert cell column for groupby.\r\n",
    "blocks_oz_df.insert(0,'cell',blocks_df['cell'])\r\n",
    "cell_oz_df = blocks_oz_df.groupby(['cell']).sum()\r\n",
    "\r\n",
    "## Export the data for visualization\r\n",
    "file_path = os.path.join('..','..','Resources','cells_oz.json')\r\n",
    "cell_oz_df.to_json(file_path)\r\n",
    "\r\n",
    "# Create gold production by position\r\n",
    "blocks_oz_df.insert(0,\"lat\",blocks_df['lat'])\r\n",
    "blocks_oz_df.insert(1,\"lng\",blocks_df['lng'])\r\n",
    "position_oz_df = blocks_oz_df\r\n",
    "position_oz_df.drop(columns = 'cell',inplace = True)\r\n",
    "position_oz_df = position_oz_df.groupby(['lat','lng']).sum()\r\n",
    "position_oz_df.reset_index(inplace = True)\r\n",
    "\r\n",
    "# Blocks cumulative gold production\r\n",
    "cumsumlist = blocks_oz_df.columns.tolist()[2:]\r\n",
    "blocks_cumsum_oz_df = blocks_oz_df.copy()\r\n",
    "blocks_cumsum_oz_df[cumsumlist] = blocks_cumsum_oz_df[cumsumlist].cumsum(axis = 1)\r\n",
    "\r\n",
    "# Blocks remaining ounces\r\n",
    "blocks_remaining_oz_df = blocks_df[['lat','lng']]\r\n",
    "blocks_remaining_oz_df[cumsumlist] = 0.0\r\n",
    "blocks_remaining_oz_df[['stack_finish','ounces_per_block']] = blocks_df[['stack_finish','ounces_per_block']]\r\n",
    "blocks_remaining_oz_df = blocks_remaining_oz_df.apply(init_oz,axis=1)\r\n",
    "blocks_remaining_oz_df.drop(columns = ['stack_finish','ounces_per_block'],inplace = True)\r\n",
    "blocks_remaining_oz_df[cumsumlist]=blocks_remaining_oz_df[cumsumlist]-blocks_cumsum_oz_df[cumsumlist]\r\n",
    "\r\n",
    "# Position remaining ounces\r\n",
    "position_remaining_df = blocks_remaining_oz_df.groupby(['lat','lng']).sum()\r\n",
    "position_remaining_df.reset_index(inplace = True)\r\n",
    "\r\n",
    "# Convert datetime columns to string\r\n",
    "date_list = position_remaining_df.columns.tolist()[2:]\r\n",
    "converted_date_list = [str(date.year)+'-'+str(date.month) if date.month>=10 else str(date.year)+'-0'+str(date.month) for date in date_list]\r\n",
    "convert_dict = dict(zip(date_list, converted_date_list))\r\n",
    "position_remaining_df.rename(columns = convert_dict,inplace = True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-17-57e3d9d9cc88>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blocks_remaining_oz_df[cumsumlist] = 0.0\n",
      "C:\\Users\\dzhang\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\dzhang\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Geojson\r\n",
    "# Define block size\r\n",
    "delta_lat = (lat_max - lat_min)/resolution[0]/2\r\n",
    "delta_lng = (lng_max - lng_min)/resolution[1]/2\r\n",
    "features = position_remaining_df.apply(\r\n",
    "    lambda row: Feature(geometry=Polygon([[\r\n",
    "        # (row['lat'] + delta_lat, row['lng'] + delta_lng),\r\n",
    "        # (row['lat'] - delta_lat, row['lng'] + delta_lng),\r\n",
    "        # (row['lat'] - delta_lat, row['lng'] - delta_lng),\r\n",
    "        # (row['lat'] + delta_lat, row['lng'] - delta_lng),\r\n",
    "        # (row['lat'] + delta_lat, row['lng'] + delta_lng)\r\n",
    "        (row['lng'] + delta_lng, row['lat'] + delta_lat),\r\n",
    "        (row['lng'] - delta_lng, row['lat'] + delta_lat),\r\n",
    "        (row['lng'] - delta_lng, row['lat'] - delta_lat),\r\n",
    "        (row['lng'] + delta_lng, row['lat'] - delta_lat),\r\n",
    "        (row['lng'] + delta_lng, row['lat'] + delta_lat)\r\n",
    "    ]])),\r\n",
    "    axis=1).tolist()\r\n",
    "\r\n",
    "properties = position_remaining_df.drop(['lat', 'lng'], axis=1).to_dict('records')\r\n",
    "\r\n",
    "for x in range(len(features)):\r\n",
    "    features[x].properties = properties[x]\r\n",
    "\r\n",
    "feature_collection = FeatureCollection(features=features)\r\n",
    "\r\n",
    "file_path = os.path.join('..','..','Resources','position_remain_oz.geojson')\r\n",
    "\r\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\r\n",
    "    json.dump(feature_collection, f, ensure_ascii=False)\r\n",
    "\r\n",
    "position_oz_df['overall_ozs'] = position_oz_df.drop(columns = ['lat','lng']).sum(axis = 1)\r\n",
    "file_path = os.path.join('..','..','Resources','latlng_oz.json')\r\n",
    "position_oz_df.to_json(file_path)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "189d9f5c1c3a73944c5bc223bc389f711b1fcf314b01e7cd9cbf0d2e857d51a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}